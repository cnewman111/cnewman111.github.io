<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">


    <!-- page icon -->
    <link rel="shortcut icon" type="x-icon" href="page_icon.jpg">

    <!-- Bootstrap -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>

    <!-- Cinzel Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Cinzel&family=Roboto&display=swap" rel="stylesheet">

    <!-- CSS Stylsheet -->
    <link rel="stylesheet" href="styles.css">

    <!-- Font awsome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin="anonymous" referrerpolicy="no-referrer" />

    <!-- JS -->
    <script defer src="scripts.js"></script>
    <title>CS 180 - Colin Newman</title>
</head>

<body>
    <!-- Navbar -->
    <nav class="navbar navbar-expand-md navbar-dark px-5 pt-2 fixed-top">
        <div class="container-fluid">
          <a class="navbar-brand fs-3" href="index.html"> CS 180 - Colin Newman </a>

          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav fs-5 ms-auto">
                <li class="nav-item">
                    <a class="nav-link" href="index.html"> Home </a>
                </li>

                <li class="nav-item">
                    <a class="nav-link" href="proj1.html"> Project 1 </a>
                </li>

                <li class="nav-item">
                    <a class="nav-link" href="proj2.html"> Project 2 </a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="proj3.html"> Project 3 </a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="proj4a.html"> Project 4 </a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="proj5.html"> Project 5 </a>
                </li>
                <li class="nav-item">
                    <a class="nav-link active" href="Final.html"> Final </a>
                </li>
            </ul>
          </div>
        </div>
    </nav>
    <!-- Navbar end -->

<!-- Landing start -->
<section id="landing">
    <div class="container-fluid h-100">
        <div class="row no-gutters h-100">
            <!-- Left side: white block with text -->
            <div class="col-md-6 d-flex align-items-center justify-content-center text-center bg-dark">
                <div>
                    <h1 class="fw-bold text-white"> Final Project </h1>
                    <p class="lead mb-4 text-white"> Neural Radiance Fields </p>
                </div>
            </div>
            <!-- Right side: image -->
            <div class="col-md-6 d-flex align-items-center justify-content-center text-center bg-secondary">
                    <img class="img-fluid rounded" src="final_assets/ray_vis.png" alt="background image of the UC Berkeley Campanile">
            </div>
        </div>
    </div>
</section>
<!-- Landing end -->

<!-- Overview start -->
<div class="container my-5">
    <div class="row align-items-center">
        <div class="col-md-5">
            <h2> Overview </h2>
            <p> In this project, I will be implementing a Neural Radiance Field (NeRF).  The idea is that using NeRFs, we can synthesize a 3D representation
                of an object from 2D pictures of an object from different angles. 
            </p>
            <p>
                NeRFs are more powerful than other forms of 3D vision, as they do not require humans to label any correspondes.  Furthermore, NeRFS create a continuous surface,
                compares to how legacy models create a polygon model of the 3D geometry.
            </p>

            <p>
                We will start by introducing NeRFs in 2D, and then expanding to the more interesting 3D use case.
            </p>
        </div>
        <div class="col-md-7 mx-auto">
            <img src="final_assets/rotating.gif" class="img-fluid" alt="aligned onion church">
        </div>
    </div>
</div>
<!-- Overview end -->

<!-- Part 1 Start -->
<div class="container my-5">
    <div class=" section-title">
        <h2> Part 1: Fit a Neural Field to a 2D Image </h2>
    </div>
    <div class="section-text">
        <p> In 2D, Neural Radiance Fields (NeRFs) are actually quite boring.  Because we have a 2D image, and the underlying "geometry" of the scene is itself in 2D, we have a perfect
            representation of the scene without having to do any geometry outselves.  All we have to do is create a neural net, and teach it to "remember" the image we feed it, pixel by pixel.  
            This is not very useful, as all the NeRF does in this case is remember (imperfectly) the original image
        </p>

        <p> I use the follwing architecture, using Sinusoidal Positional Encoding with L=10, 4 linear layers, a channel size of 256, a learning rate of .01, and the ADAM optimizer:
        </p>
    </div>
    <div class="row">
        <div class="col-md-12 mb-3">
            <img src="final_assets/mlp_img.jpg" alt="Photo 1" class="photo img-fluid">
        </div>
    </div>

    <div class="section-text">
        <p> Here is an example using a fox after training on the network detailed above at various iterations:
        </p>
    </div>

    <div class="row">
        <div class="col-md-6 mb-3">
            <img src="final_assets/fox.jpg" alt="Photo 1" class="photo img-fluid">
            <p> Original Image </p>
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/1Iteration.png" alt="Photo 1" class="photo img-fluid">
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/100Iteration.png" alt="Photo 2" class="photo img-fluid">
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/500Iteration.png" alt="Photo 2" class="photo img-fluid">
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/1000Iteration.png" alt="Photo 2" class="photo img-fluid">
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/5000Iteration.png" alt="Photo 2" class="photo img-fluid">
        </div>
    </div>

    <div class="section-text">
        <p> Since we have perfect data, the network almost perfectly aproximates the image, as expected.
        </p>
    </div>

    <div class="section-text">
        <p> Here is the Peak Signal-to-Noise Ration (PSNR) curve for the training loop:
        </p>
    </div>

    <div class="row">
        <div class="col-md-12 mb-3">
            <img src="final_assets/psnr_fox.png" alt="Photo 1" class="photo img-fluid">
        </div>
    </div>

    <div class="section-text">
        <p> Here is another example with another picture.  This time, I varied some of the parameters from the default values I stated above.
        </p>
    </div>

    <div class="row">
        <div class="col-md-6 mb-3">
            <img src="final_assets/mountains.jpg" alt="Photo 1" class="photo img-fluid">
            <p> Original Image </p>
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/mountains_learned.png" alt="Photo 1" class="photo img-fluid">
            <p> Default Network </p>
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/lr_point_1.png" alt="Photo 2" class="photo img-fluid">
            <p> Learning rate = .1 (Fails to Converge) </p>
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/lr_point_zero_zero_1.png" alt="Photo 2" class="photo img-fluid">
            <p> Learning rate = .001</p>
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/128_layers.png" alt="Photo 2" class="photo img-fluid">
            <p> Lowering Channels to 128 </p>
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/512_layers.png" alt="Photo 2" class="photo img-fluid">
            <p> Increasing Channels to 512 </p>
        </div>
    </div>

    <div class="section-text">
        <p> Here is the PSNR curve for the original network, with learning rate = .01 and 256 channels:
        </p>
    </div>

    <div class="row">
        <div class="col-md-12 mb-3">
            <img src="final_assets/psnr_mountains.png" alt="Photo 1" class="photo img-fluid">
        </div>
    </div>

</div>

<!-- Part 1 End -->

<!-- Part 2 Start -->
<div class="container my-5">
    <div class=" section-title">
        <h2> Part 2: Fit a Neural Radiance Field from Multi-view Images </h2>
    </div>
    <b> 2.1: Create Rays from Cameras
    </b>

    <p> Camera to World Coordinate Conversion: This is simply using the given matricies in the dataset to batch multiply the camera coordinates into the world coordinate frame. </p>
    <p> Pixel to Camera Coordinate Conversion: Mathmatically, you can take intrinsic matrix derived from the focal length and prinicple point and multiply its inverse against the pixels to transform them into the camera coordinate frame.  In practice, I used torch.linalg.solve for efficency and robusticity reasons. </p>
    <p> Pixel to Ray: The rotation matrix can be determined by inverting camera_to_world, and again inverting the submatrix of camera_to_world that represents the inverted rotation component of the transformation.  Then, I solve for the origin ray, and use the two functions exlplained above to solve for the direction ray.  </p>

    <b> 2.2: Sampling
    </b>
    <p> My method of sampling was to take all of the pictures in the training set, flatten them, and randomly sample indicies.  From there the previously defined functions could be used to retrieve the rays and rgb values.</p>
    <p> From there, I discretized the rays with 64 samples over the range 2-6, therby adding a sample dimension to the input tensor. </p>


    <b> 2.3 Putting the Dataloading All Together: </b>
    <p> Here is a visualization of the entire ray creation and sampling process.  Pictured are the frustrum of each camera, the 100 globally randomly sampled rays, and the samples along the rays. </p>

    <div class="row">
        <div class="col-md-12 mb-3">
            <img src="final_assets/ray_vis.png" alt="Photo 1" class="photo img-fluid">
        </div>
    </div>

    <b> 2.4 Neural Radiance Field: </b>
    <p> I made no changes to the suggested architecture, as it already acheived desired results when properly implemented.  L=4 on the PE layer:  </p>

    <div class="row">
        <div class="col-md-12 mb-3">
            <img src="final_assets/mlp_nerf.png" alt="Photo 1" class="photo img-fluid">
        </div>
    </div>

    <b> 2.5: Volume Rendering</b>
    <p> I implemented the following discrete volume rendering equation with batching: </p>
    <div class="row">
        <div class="col-md-2 mb-3">
            <img src="final_assets/Screenshot 2024-12-13 at 9.55.44â€¯PM.png" alt="Photo 1" class="photo img-fluid">
        </div>
    </div>

    <b> Final Results </b>
    <p> Here are some views rendered at various times throughout the training process: </p>
    <div class="row">
        <div class="col-md-6 mb-3">
            <img src="final_assets/1it.png" alt="Photo 1" class="photo img-fluid">
            <p> Iteration 1 </p>
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/100it.png" alt="Photo 2" class="photo img-fluid">
            <p> Iteration 100 </p>
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/500it.png" alt="Photo 2" class="photo img-fluid">
            <p> Iteration 500 </p>
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/2000it.png" alt="Photo 2" class="photo img-fluid">
            <p> Iteration 1000 </p>
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/5000it.png" alt="Photo 2" class="photo img-fluid">
            <p> Iteration 5000 </p>
        </div>
    </div>

    <p> Here are the PSNR curvers for training and validation: </p>
    <div class="row">
        <div class="col-md-6 mb-3">
            <img src="final_assets/training_loss.png" alt="Photo 1" class="photo img-fluid">
        </div>
        <div class="col-md-6 mb-3">
            <img src="final_assets/validation_loss.png" alt="Photo 1" class="photo img-fluid">
        </div>
    </div>

    <p> Finally, we can render the object from any view we choose, even if there was not a camera pointed in that direction!: </p>
    <div class="row">
        <div class="col-md-2 mb-3">
            <img src="final_assets/rotating.gif" alt="Photo 1" class="photo img-fluid">
        </div>
    </div>
    
</div>

<!-- Part 2 End -->



</body>